2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-05-05', 'title': '上海本地西瓜甜瓜成熟上市，购买攻略来了！'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海本地西瓜甜瓜成熟上市，购买攻略来了！' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-05-05', 'title': '上海交大安保员考上本校研究生，29岁完成黑马逆袭'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海交大安保员考上本校研究生，29岁完成黑马' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '同济大学学生午餐盒饭中疑似吃出猪肉绦虫卵、猪毛、昆虫及蜗牛等异物',
 'times': '2022-05-05',
 'title': '同济大学盒饭里有猪毛和昆虫？咸猪肉生产商、供应商涉嫌违法'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '同济大学盒饭里有猪毛和昆虫？咸猪肉生产商、' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-05-05', 'title': '上海第二版复工复产疫情防控指引来了！这几方面有更新调整'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海第二版复工复产疫情防控指引来了！这几方' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '多位上海市民反映收到团购的一点点奶茶，发现杯上贴纸显示为杭州门店制作',
 'times': '2022-05-05',
 'title': '跨省团购“隔夜奶茶” 一点点缘何有现做奶茶流入市场？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '跨省团购“隔夜奶茶” 一点点缘何有现做奶茶流' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-05-05', 'title': '上海保供：买菜还难吗？物价怎么稳？礼包如何管？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海保供：买菜还难吗？物价怎么稳？礼包如何' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '中药防疫干预的汤药怎么服用，什么时候、什么人群可以服用',
 'times': '2022-05-05',
 'title': '中药预防方如何服用？普通上呼吸道疾病如何与新冠区分？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '中药预防方如何服用？普通上呼吸道疾病如何与' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': None,
 'times': '2022-05-05',
 'title': '5月4日（0-24时）上海新增本土确诊病例261例、无症状感染者4390例，出院...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '5月4日（0-24时）上海新增本土确诊病例261例、无' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-05-05', 'title': '这些消毒方法都错了，侬晓得伐？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '这些消毒方法都错了，侬晓得伐？' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '妻子出来后，两人把大部分物资搬上了物业开来的卡车上，一少部分放在电瓶车上，主要是小孩的奶粉、冰淇淋。赵巷派出所民警唐鑫告诉记者，5月1日以来，赵巷派出所每天调配一名民警、3名辅警在山姆会员商店附近维护道路秩序，提醒排队的居民保持2米间距，正确佩戴口罩。',
 'times': '2022-05-05',
 'title': '“开了辆卡车过来，拉小区居民买的物资”|探访青浦山姆超市'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“开了辆卡车过来，拉小区居民买的物资”|探访' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '5月4日，在首个实现社会面基本清零的中心城区普陀区，万里街道率先在坚持从严管理基础上，落实适当放开。万里街道已为20个防范区小区进行统筹安排，确保每个小区都能获得不同时段出入居民区的机会。',
 'times': '2022-05-05',
 'title': '普陀防范区居民出门首日直击 | 首批居民今早8时走出小区，市特有的烟火 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '普陀防范区居民出门首日直击 | 首批居民今早8时' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '自3月以来，上海各级政府利用体育场馆、展览场馆、学校等设施改建或新建超过200家方舱医院，提供床位数超30万张。“上海环境”给出了方案：通过制定技术标准，按照循环利用、再生资源利用、末端安全处置“三部曲”，安全、低碳、环保地让一座座“退役”方舱医院涅槃重生。',
 'times': '2022-05-05',
 'title': '“退役”方舱医院的海量废弃物去哪儿了？“上海环境”多管齐下实施低碳 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“退役”方舱医院的海量废弃物去哪儿了？“上' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': None,
 'times': '2022-05-05',
 'title': '疗愈身心！让大自然温暖疫情期间的你，辰山植物园推出《自然辰光》云游 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '疗愈身心！让大自然温暖疫情期间的你，辰山植' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '在上海市松江区圆通大港网点，这个五一假期，快递员阮理江终于等到了近一个月的首批进港包裹。”\u3000\u3000'
         '来自圆通的数据统计显示，目前圆通在上海复工的网点已超过十分之一，这两天圆通速递进入上海的快递包裹累计超过5万件，还在持续回升中。',
 'times': '2022-05-05',
 'title': '保供、保通、保畅，上海快递业复工将分三步走！首批包裹已陆续抵沪，收 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '保供、保通、保畅，上海快递业复工将分三步走' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-05-05', 'title': '追踪跨省“团奶茶”：8000杯抵沪已隔夜，品牌方直呼慎选'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '追踪跨省“团奶茶”：8000杯抵沪已隔夜，品牌方' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '美国疾病控制和预防中心最新数据显示，虽然变异新冠病毒奥密克戎毒株的亚型BA.2仍然是美国主要流行毒株，但另一种新亚型BA.2.12.1导致的感染病例正在快速上升。”\u3000\u3000'
         '前白宫新冠病毒应对工作组协调员黛博拉博士表示，美国南方各州可能出现的夏季新冠病例激增，政府应该做好准备。',
 'times': '2022-05-05',
 'title': '奥密克戎新毒株仍在不断进化中，最怕的是新变种传播力可能更强'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '奥密克戎新毒株仍在不断进化中，最怕的是新变' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '上海外滩仅对援沪医疗队开放。请大白们看看上海的夜景。车厢里的援沪医疗队员也是兴奋不已。司机师傅载她们去\u3000\u3000'
         '距离不过2-3公里的迪士尼打卡。司机师傅只能让我们在高架桥上\u3000\u3000远远地打卡一下迪士尼。',
 'times': '2022-05-05',
 'title': '五一假期的外滩，你们值得独享！司机故意绕路，也有暖心真相'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '五一假期的外滩，你们值得独享！司机故意绕路' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '是黄蝶此时此刻的心情。虽然来上海后几乎接触不到外界的人，但黄蝶知道，这些果蔬会通过门店送到上海市民的手中，“这就是我们来援助上海的意义呀。她和同伴没有看过这个视角的上海，街道安静，树和花也安静，而阳光和风一起，整个世界仿佛都律动起来。',
 'times': '2022-05-05',
 'title': '拨云见日，被援沪女孩的天台合影治愈了'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '拨云见日，被援沪女孩的天台合影治愈了' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '5月1日下午，网络上流传一则视频，一男子在沪青平公路加油站附近马路中央拦车，对着经过的司机说：“快要饿死了。近日，江苏苏州高新区公安分局狮山派出所接到了市民小薛报警，称其在网上报名“方舱志愿者”被骗了。',
 'times': '2022-05-05',
 'title': '上海一老人“快饿死了”拦路乞食？真相是：喝多了'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海一老人“快饿死了”拦路乞食？真相是：喝' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '为提升文旅场所健康核验和入场登记的精准性和有效性，方便市民日常通行的同时提供更高质量的文旅服务，本市文旅场所已全面部署“场所码”或“健康核验一体机” '
         '（又称“数字哨兵”）服务。',
 'times': '2022-05-05',
 'title': '上海A级景区、图书馆、文化馆等推出“场所码”，使用指南来了'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海A级景区、图书馆、文化馆等推出“场所码”' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '近日，闵行警方侦破一货运司机哄抬运费的案件。犯罪嫌疑人杨某（男，36岁）因涉嫌非法经营罪已被依法采取刑事强制措施。杨某先后以不同理由向李先生索要额外费用，最终，李先生为获得相应服务，共计支付运费2400元。',
 'times': '2022-05-05',
 'title': '上海警方：谈好的运费涨了8倍，货运司机哄抬运费被采取刑事措施'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海警方：谈好的运费涨了8倍，货运司机哄抬运' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '为做好防疫，在门店复工后，喜茶每天早中晚会对门店全场进行消杀。继海底捞之后，呷哺呷哺和湊湊的部分门店也已经复工，提供火锅和茶饮的团购和美团外卖业务，配送范围覆盖上海市主要区域。',
 'times': '2022-05-05',
 'title': '熟悉的快乐正在回来！光明邨鲜肉月饼、喜茶、火锅……'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '熟悉的快乐正在回来！光明邨鲜肉月饼、喜茶、' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '疫情之下，配送寄递人员的防疫安全成为关注重点。5月2日晚，浦东警方开展骑手集中夜宿点清查行动。民警告知骑手，这样夜宿于外，既不安全，环境也不好，政府部门有多处集中安置点，里面有基础生活设施。',
 'times': '2022-05-05',
 'title': '别睡桥洞啦，浦东已推出4个骑手集中安置点'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '别睡桥洞啦，浦东已推出4个骑手集中安置点' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '2022年5月2日，在上海市浦东新区惠南镇海沈村的瓜农们正在忙着采收8424西瓜。农户们用三轮车将西瓜运到封控的村口处，然后由大货车转运至全市各区。栏目主编：张春海 '
         '文字编辑：张陌 题图来源：孟雨涵 图片编辑：张驰 编辑邮箱：8903168@qq.com',
 'times': '2022-05-05',
 'title': '南汇8424西瓜全面开售 线上销售最快1小时从田头到家门口'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '南汇8424西瓜全面开售 线上销售最快1小时从田头' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '本轮疫情社会面清零后，上海将进入常态化防控阶段，5月1日至6月30日开展免费的常态化核酸检测。上海白泽医学检验所3月底获得新冠病毒核酸检测资质后，PCR基因检测设备从2台增至20台，按混检每管20人份估算，检测能力超过50万人份/天。',
 'times': '2022-05-05',
 'title': '现场直击：上海加速提升核酸检测能力，硬气膜实验室通宵建成'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '现场直击：上海加速提升核酸检测能力，硬气膜' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '随着疫情发展，上海全市医废、涉疫垃圾的收集、运输和处置为全市疫情防控带来巨大压力。4月30日，位于上海浦东老港医废处置基地的焚烧炉在疫情期间满负荷不间断地运转。5月1日，在上海浦东老港医废处置基地车间内，机械臂将医废倒入焚烧装置。',
 'times': '2022-05-05',
 'title': '上海：为医废、涉疫垃圾筑牢“末端防线”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海：为医废、涉疫垃圾筑牢“末端防线”' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '当前已经到了疫情防控攻坚的关键时刻，为了落实好疫情防控专业性消杀与保障重点场所复工复产预防性消杀齐头并进，静安置业集团组建的百人专业消杀团，不断升级壮大，以更规模化、专业化、多元化的姿态，成为疫情防控和复工复产的坚实“守护者”。4月26日开始，置业集团增派定点消杀队伍，针对涉阳楼栋、涉阳门户及小区重点开展终端消杀工作。',
 'times': '2022-05-05',
 'title': '消杀再升级！为复工复产织密筑牢疫情防护“置业网络”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '消杀再升级！为复工复产织密筑牢疫情防护“置' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '随着防控时间的延长，居民会出现各种各样的临时需求，无论何种需求，到了严婷那里都可以得到圆满的解决。”\u3000\u3000'
         '如今的严婷俨然成了疫情期间小区居民最乐于天天见的一颗“定心石”。',
 'times': '2022-05-05',
 'title': '徐汇这个小区从来没有出现过一例阳性！无疫家园是如何做到的？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '徐汇这个小区从来没有出现过一例阳性！无疫家' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '毕业季即将来临，近日话题#211大学女硕士二次择业选择修脚#登上热搜，关于名校研究生的就业现状问题再次引起了人们的热议。我们聚焦长三角8所985高校复旦大学、上海交通大学、同济大学、华东师范大学、南京大学、东南大学、浙江大学以及中国科学技术大学，分析这几个学校的2021届研究生就业情况。',
 'times': '2022-05-05',
 'title': '江浙沪皖985高校的研究生工作好找吗？最爱去哪个行业？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '江浙沪皖985高校的研究生工作好找吗？最爱去哪' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '闭环管理前期，居民用药需求还不是很多，如有特殊情况可寻求居委会代配药志愿者帮助。由于居民登记的配药清单中有部分是处方药，平台通过医生为患者提供在线问诊服务，以纾解因疫情封控带来的“配药难”问题。',
 'times': '2022-05-05',
 'title': '在这个居民区，配药也有“团长”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '在这个居民区，配药也有“团长”' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '近日，上海越来越多门店开始在外卖平台上恢复营业。原来，一位便利店店长一直看到有网友说“想念全家开门的声音”，于是她用店面开门的乐谱“752562 '
         '67625”来回复评论区的顾客。',
 'times': '2022-05-05',
 'title': '上海这位便利店店长的神秘回复，太暖了'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海这位便利店店长的神秘回复，太暖了' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '该区农业农村委向新区政府、市农业农村委寻求支持，同时与各镇加强沟通，对村委会等加强协调，以“结对子”的方式缓解销售难题。大润发的介入及时纾解了地产瓜果的滞销难题，不过，对惠南镇来讲，还有更大的考验摆在眼前。',
 'times': '2022-05-05',
 'title': '吃瓜群众在哪里？上海农户喊你来买瓜了'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '吃瓜群众在哪里？上海农户喊你来买瓜了' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '虹口区广灵二路264弄海怡花园小区，是疫情封控以来本市第一批明确的防范区。图说：退役军人、军嫂等是小区疫情封控的生力军 '
         '采访对象供图（下同）目前，海怡花园的退役军人志愿者队伍不断壮大，仅在居委会登记的退役军人志愿者就达30多人。',
 'times': '2022-05-05',
 'title': '这个“无疫小区”有何妙招？“军”字招牌发挥了作用'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '这个“无疫小区”有何妙招？“军”字招牌发挥' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '“一条生产线日产1万箱青柠汁，目前出口正常。值得一提的是，3月中旬，为了感谢“疫”线人员在封控小区的坚守，上海泛迎食品科技有限公司捐赠了2400瓶小青柠饮料，诠释了小企业的大担当。',
 'times': '2022-05-04',
 'title': '青柠汁、焦糖黑糖饼干……金山这些美味的“回归”，离不开“金牌快递员”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '青柠汁、焦糖黑糖饼干……金山这些美味的“回' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '2022年5月3日0—24时，新增本土新冠肺炎确诊病例260和无症状感染者4722例，其中151例确诊病例为既往无症状感染者转归，108例确诊病例和4660例无症状感染者在隔离管控中发现。',
 'times': '2022-05-04',
 'title': '5月3日（0-24时）上海新增本土确诊病例260例、无症状感染者4722例，出院...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '5月3日（0-24时）上海新增本土确诊病例260例、无' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '当下，黄浦商场虽然还未开门迎客，但里面却已开始忙碌起来。BFC外滩金融中心，最近迎来了上海滩餐厅、捞王、莆田、潮民公馆等品牌的复工，开启团购配送。在上海新天地，席隆、吉士星座、一坐一忘云南菜等餐饮品牌也开始“闭门营业”，为周边居民提供团购套餐。',
 'times': '2022-05-04',
 'title': '黄浦这些商场开启“闭门营业”！'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '黄浦这些商场开启“闭门营业”！' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '截至4月30日，奉贤全区1002个场所已布设“数字哨兵”，共计1639套设备，累计扫码量847万人次；19444个场所已完成“场所码”部署，共计申领21397张，累计扫码量231.3万人次。4、将“场所码”下载打印张贴在场所出入口，出入人员只要扫一扫，即可完成人员信息登记、人员健康状态核验，方便单位做好防控核查工作。',
 'times': '2022-05-04',
 'title': '“场所码” “数字哨兵”为防疫上“保险”，快速便捷，老年人也毫无压力'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“场所码” “数字哨兵”为防疫上“保险”，快' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '市场监管部门已立案调查当事人，于5月1日送达行政处罚告知书，对其价格违法行为作出警告，并处罚款8万元。当事人上述涉案产品的进销差价率远高于同时期周边市场同类商品的进销差价率。',
 'times': '2022-05-04',
 'title': '肉店冒充上农批卖“土猪肉”，联华超市加盟商哄抬菜价，一批违法经营者曝光'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '肉店冒充上农批卖“土猪肉”，联华超市加盟商' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '“这些保供物资具体囊括哪些，是我们在线上征求居民区建议后，确定下来的。“我们线上线下总动员，尽全力保障老人们的生活物资供给。而在线下，街道一方面对接爱心企业，为独居老人、低保户家庭等特殊人群送去关爱。',
 'times': '2022-05-04',
 'title': '生活物资保供，看看这个街道是怎么做的'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '生活物资保供，看看这个街道是怎么做的' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:13 [scrapy.core.scraper] ERROR: Error processing {'info': '4月19日，在街道“拔点”工作专班、社区居委和志愿者的努力下，丰庄西路433弄小区所有阳性确诊病例完成转运。”\u3000\u3000'
         '考虑到就医配药工作的专业性，金沙社区特地请来社区居民、退休全科医生仇兰娣帮忙。',
 'times': '2022-05-04',
 'title': '清零攻坚在行动丨从30例确诊到“无疫小区”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '清零攻坚在行动丨从30例确诊到“无疫小区”' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '早上9点，奉贤区育秀路恢复了一些往常的烟火气。记者在奉贤多处看到，沿街商铺也已有不少恢复营业，肯德基、麦当劳、必胜客，还有奶茶店、面包店、母婴用品店等都迎来了久违的顾客。',
 'times': '2022-05-04',
 'title': '上海这个区肯德基奶茶店都开业了？世纪联华迎来顾客，活蹦乱跳鱼虾惹人爱'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海这个区肯德基奶茶店都开业了？世纪联华迎' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '5月1日，上海的奉贤、金山、青浦、崇明、松江和普陀六个区实现社会面基本清零——在做好“三区“管控同时，开始“有限人员、有限区域、有限活动”。”\u3000\u3000'
         '蔷薇社区南门和北门都设了核酸检测点，采样志愿者的“大白“陆续穿好，顾亚香不停地叮嘱：“记得戴两层手套，第一手套压着自己的衣服，第二手套压着防护服。',
 'times': '2022-05-04',
 'title': '感受松江基本清零区，正常生活谨慎地渐行渐近'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '感受松江基本清零区，正常生活谨慎地渐行渐近' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '——林明杰\u3000\u3000这个云摄影展发布以后一下子刷爆朋友圈，引起了无数人的共鸣，全国的朋友们都来观赏留言。',
 'times': '2022-05-04',
 'title': '“葱”明！上海人给葱办了一个摄影展'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“葱”明！上海人给葱办了一个摄影展' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '今日，上海市测绘院推出了常态化核酸采样点地图2.0版，更新核酸采样点位数据、优化完善了功能，让用户随时随地查询上海市所有核酸采样点信息。在新版地图中更新了核酸采样点位数据、优化完善了功能，操作使用更加便捷、用户体验更加舒适。',
 'times': '2022-05-04',
 'title': '一图查询1131个点 上海常态化核酸采样点地图2.0版上线'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '一图查询1131个点 上海常态化核酸采样点地图2.0' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '上海警方持续开展“黑骑手”专项整治行动，针对重点路段、商业网点周边及桥洞、地铁站等外卖快递骑手临时集中休息点等加大检查力度，确保“逢车必检、逢人必查”。日前，金山公安分局民警在蒙山路、龙胜路查获一骑手吴某（男，23岁）着便装载着某外卖平台配送包配送外卖，形迹可疑，且无“电子通行证”。',
 'times': '2022-05-04',
 'title': '上海警方查获“黑骑手”828人，535人被行政处罚'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海警方查获“黑骑手”828人，535人被行政处罚' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '穿上防护服，说着普通话……在抗击疫情的一线，来自上海市浦南医院国际部的外籍医生们，与中国“大白”并没有什么两样。“欧巴”朴永镇医生是个“中国女婿”，从3月12日开始就加入了社区采样队，已经去过昌里花园、金桥路、艾南花苑、国展路等7个点位。',
 'times': '2022-05-04',
 'title': '“我想尽一份力，让自己热爱的上海早日回归正常生活！”外籍医生积极投 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“我想尽一份力，让自己热爱的上海早日回归正' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '全国多地蓝天救援队员集结上海，支援消杀工作。本文图片均为上海市民防办图\u3000\u3000'
         '5月1日，上海民防蓝天救援疫情防控突击队在黄浦区外滩街道开展了一次“抗疫援沪”集中消杀行动。后续，各队将在上海蓝天救援队的协调下，根据各驻点街镇和跨区支援需求，持续开展相关任务。',
 'times': '2022-05-04',
 'title': '全国多地蓝天救援队员集结上海，将根据需求持续开展消杀任务'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '全国多地蓝天救援队员集结上海，将根据需求持' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '早上8点，周挺和老公从家中出发，开车来到上海瑞金医院，直奔大厅的自助挂号机，掏出随身携带的23张医保卡，依次塞进机器内。配药的前一晚，我得核对Excel表格上用药人的所有信息，还要核对结算清单。',
 'times': '2022-05-04',
 'title': '上海抗疫口述实录｜配药志愿者周挺：23张医保卡，10家养老机构，我给“ ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海抗疫口述实录｜配药志愿者周挺：23张医保' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '“口罩爆珠”的珠子主要以精油制成，捏爆珠子后精油挥发，会产生清凉功效；“口罩鼻托”、“口罩防雾条”：硅胶或海绵质地，撕开胶贴，将鼻托粘在口罩鼻梁位置，主要解决戴口罩时，眼镜被雾气困扰的问题；',
 'times': '2022-05-04',
 'title': '“口罩防闷神器”走红，真的有用吗？医生：慎用'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“口罩防闷神器”走红，真的有用吗？医生：慎' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '4月28日，闵行成立区、街镇（工业区）两级流行病学调查联合工作组。下一步，工作组将明确“四张”清单，完善社会面三级疫情防控网，提升全区整体疫情处置能力，助推疫情防控工作精准、有序、扎实落地。',
 'times': '2022-05-04',
 'title': '三级网络 四张清单！流调队伍下沉社区，这些疫情防控要点你注意到没？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '三级网络 四张清单！流调队伍下沉社区，这些疫' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '预约式限流实体店营业\u3000\u3000'
         '会员需提前在山姆App上获取“Sam实体店进店预约码”，每天每人限额一件，持有预约码及居委发放的绿色购物证、核酸阴性证明等才能进店购物。',
 'times': '2022-05-04',
 'title': '笑出眼泪！上海重现80年代街景！扁担成购物神器'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '笑出眼泪！上海重现80年代街景！扁担成购物神' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '2022年5月2日0—24时，新增本土新冠肺炎确诊病例274和无症状感染者5395例，其中155例确诊病例为既往无症状感染者转归，117例确诊病例和5324例无症状感染者在隔离管控中发现。',
 'times': '2022-05-03',
 'title': '5月2日（0-24时）上海新增本土确诊病例274例、无症状感染者5395例，出院...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '5月2日（0-24时）上海新增本土确诊病例274例、无' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '首末站方案：周家嘴路军工路站、中山公园地铁站2处首末站，拟设置在周家嘴路/军工路、汇川路/凯旋路近路口位置，与地块现状设施或规划建筑设施结合建设。停保场方案：规划北横中运量公交拟利用现状内江路停保场进行车辆停靠、维修、保养等。',
 'times': '2022-05-03',
 'title': '上海规划北横中运量公交线，拟周家嘴路军工路站至中山公园地铁站，约16....'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海规划北横中运量公交线，拟周家嘴路军工路' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '超市、快递物流、汽车和船舶制造等各行各业在做好疫情防控的前提下，已陆续有序复工。组织重点场所，在复工复产前进行全面清洁消毒；复工复产后，严格落实预防性消杀等防控措施。',
 'times': '2022-05-03',
 'title': '直击防范区超市重开、居民出门！窗外银杏叶绿了，夏木阴阴正可人'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '直击防范区超市重开、居民出门！窗外银杏叶绿' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '在抗疫的特殊日子里，上海S20外环高速上，有一群迎难而上、坚守岗位的建设者。随着S20外环高速沪青平立交（西幅）抢修工程顺利完成，平整的桥面上，交通标线清晰而醒目，静待即将复苏的滚滚车流。',
 'times': '2022-05-03',
 'title': 'S20外环高速沪青平立交（西幅）抢修完工了！桥面更加平整，交通标线清晰...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'S20外环高速沪青平立交（西幅）抢修完工了！桥' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '今天，国家会展中心（上海）方舱医院出院出舱7500人左右，据此，从这里出院出舱的总人数已累计突破10万人，达到10.6万人。国家会展中心（上海）方舱医院是上海最大的方舱医院，提供超过5万张床位，于4月9日正式启用，迎来首批新冠肺炎感染者。',
 'times': '2022-05-03',
 'title': '上海最大方舱医院出舱总人数突破10万，陈尔真：“情况越来越好转！”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海最大方舱医院出舱总人数突破10万，陈尔真' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '是可忍孰不可忍，李子柒对此发表声明称，根据法律规定，“李子柒”及其派生权益受法律保护，任何组织或者个人不得非法侵犯。在抖音上搜索“李佳佳”可以发现，会出现很多同名的账号，有的粉丝几个，有的粉丝几千，有的也有几十万，而很多账号还是用的李子柒头像。',
 'times': '2022-05-03',
 'title': '停更290天，李子柒突然发声：让背后花钱的人失望了'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '停更290天，李子柒突然发声：让背后花钱的人失' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '在辰山植物园内，月季主要分布在月季园、空中月季花园和月季花墙，总占地面积约36000平方米，展示了1000多种现代月季品种、蔷薇原种和玫瑰品种。月季花墙位于辰山山脚（电瓶车矿坑花园站至岩石和药用植物园站之间），有长达1500米的月季花墙，也以成为园区网红打卡地之一。',
 'times': '2022-05-03',
 'title': '辰山“花中皇后”陆续绽放，一起来“云赏花”！'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '辰山“花中皇后”陆续绽放，一起来“云赏花”' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '”\u3000\u3000'
         '据张化珂说，他们会把做好的饭菜打包好，放在封控区的路口边，接下来的工作由防疫工作人员统一再分配调度。张化珂是一名退伍军人，他曾当兵5年，在炊事班呆过一年，“我按照部队上的标准，严格要求食材、卫生，色香味俱全。',
 'times': '2022-05-03',
 'title': '张化珂，你火上热搜了'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '张化珂，你火上热搜了' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '陈新，57岁，上海市公安局刑事科学技术研究管理中心副主任，一名具有三十多年工作经验的资深法医专家，人称“老党员”。”\u3000\u3000'
         '从4月8日开始，陈新就带领2名同事，守护着近3000名患者的国展中心1.1号馆方舱。',
 'times': '2022-05-03',
 'title': '一位留美归国女孩的方舱经历：虽然承受了委屈，也会有不凡的收获'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '一位留美归国女孩的方舱经历：虽然承受了委屈' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '随着上海本轮疫情防控取得阶段性成效，复工复产正有力有序推进。统筹长三角地区产业链供应链重点企业名单，实现“白名单”企业五关互认，建立统一的绿色通道，实现通关手续从快从简。',
 'times': '2022-05-03',
 'title': '全力以“复”！沪苏浙皖一起做了这些事，按下复工复产加速键'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '全力以“复”！沪苏浙皖一起做了这些事，按下' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '5月1日，南沿江铁路常熟站混凝土主体结构提前一个月完成封顶，施工现场一片繁忙景象。截至目前，中国铁路上海局集团有限公司已累计完成建设投资221.26亿元，一批重点项目建设迎来新进展。',
 'times': '2022-05-03',
 'title': '节日坚守不停工 长三角铁路重点项目迎来新进展'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '节日坚守不停工 长三角铁路重点项目迎来新进展' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '5月1日0时刚过，凤阳路415号的长征医院核酸检测点，声浪越发汹涌。截至4月30日，上海最新已有1131个常态化核酸采样点提供免费检测，长征医院这个核酸检测点榜上有名。记者多次在此核酸检测，索性当起志愿者，指导小哥们更快开单，也提醒他们享受免费核酸政策。',
 'times': '2022-05-03',
 'title': '直击：上海核酸免费新政让快递小哥合不拢嘴，“一个月多个800元大红包”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '直击：上海核酸免费新政让快递小哥合不拢嘴，' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '4月29日凌晨3点，江苏省援沪应急采样队江苏省人民医院分队又整装出发了，目的地浦东沪东新村街道。”\u3000\u3000'
         '记者了解到，作为领队，高春红几乎每天凌晨都在和支援点位对接，确认人数和点位、安排采样，等到队伍出发，有时只能睡上几个小时。',
 'times': '2022-05-03',
 'title': 'N次奔赴，双向感动！来看江苏省援沪应急采样队这支小分队的“浦东故事”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'N次奔赴，双向感动！来看江苏省援沪应急采样队' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '这场没有硝烟的战“疫”中，涌现出了太多的感人故事，那些积极互助、相互守护、共渡难关的“近邻”之情更是令人感动。我们没有气壮山河的豪言壮语，也没有惊天动地的英雄壮举，但那些平凡的故事，却因坚守与担当，而展现出不一样的光芒......',
 'times': '2022-05-03',
 'title': '疫情下，普陀这个社区“熟”出了新高度'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '疫情下，普陀这个社区“熟”出了新高度' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '对于教师志愿者赵艳坤而言，这一天原本计划和未婚夫携手步入婚姻殿堂，但因为上海疫情当前，准备已久的婚礼“泡汤”了。随着疫情起伏反复，清明小长假期间，校区提级管理之后，赵艳坤又加入学校长宁防疫工作专班。',
 'times': '2022-05-03',
 'title': '跨越河南辽宁上海办成“云婚礼”，防疫专班海归女博士闭环50天与他终成眷属'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '跨越河南辽宁上海办成“云婚礼”，防疫专班海' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '在张江科学城，有一个130多人的团队坚守在园区，其中很多人已一个多月没有回家。解放日报·上观新闻记者今天身着“大白”防护服，走进上海实验动物研究中心园区，见到了在那里忙碌的工作人员以及很多灵动的老鼠和鱼儿。以这些保种品系为基础，上海实验动物研究中心每年的小鼠和大鼠产量多达100万只。',
 'times': '2022-05-03',
 'title': '为了实验鼠和斑马鱼，上海130多人团队坚守张江园区一个多月'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '为了实验鼠和斑马鱼，上海130多人团队坚守张江' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '随着疫情防控和复工复产工作的持续推进，徐汇区的商超便利店、餐饮、药店等重要保供力量正在加快恢复供应能力。徐汇融媒记者从相关部门获悉，截至4月29日，区域内在营店铺共546家，线上接单店铺613家，49个电商平台网点正常运营。',
 'times': '2022-05-03',
 'title': '徐汇区613家商超便利店、餐饮店铺恢复线上营业，实测下单2小时可送达'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '徐汇区613家商超便利店、餐饮店铺恢复线上营业' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '因售卖的“JGHLZ精戈速溶咖啡”（下称：精戈咖啡）被检测出含有西地那非成分，山东省烟台市牟平区的姜女士被买家张某起诉，要求“退一赔十”。4月29日，张某就其打假行为回复澎湃新闻称，姜女士网店销售的咖啡系有毒有害食品，且其行为受法律保护和支持。',
 'times': '2022-05-03',
 'title': '女子代发含“伟哥”咖啡遭打假被判赔30万，上游卖家已判刑'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '女子代发含“伟哥”咖啡遭打假被判赔30万，上' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '81岁的黄炜原是上海美术电影制片厂的导演，还曾担任经典动画电影《天书奇谭》的美术设计。十多天来，不论刮风下雨，江忠总是精神饱满准时出现，带着黄炜去医院。除了送黄炜去医院，江忠对小区其他老人也很照顾。',
 'times': '2022-05-03',
 'title': '52岁的邻居“小伙”，成了我在疫情中看病的120专车司机'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '52岁的邻居“小伙”，成了我在疫情中看病的120' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '2022年5月1日0—24时，新增本土新冠肺炎确诊病例727和无症状感染者6606例，其中529例确诊病例为既往无症状感染者转归，198例确诊病例和6548例无症状感染者在隔离管控中发现。',
 'times': '2022-05-02',
 'title': '5月1日（0-24时）上海新增本土确诊病例727例、无症状感染者6606例，出院...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '5月1日（0-24时）上海新增本土确诊病例727例、无' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '木绣球植株高大，在初开时颜色是清新的绿色，随着时间的推移，慢慢舒展开来，花团渐大，最后如团团白雪缀在枝头。木绣球属于忍冬科荚蒾属落叶或半常绿灌木，高可达4米，而绣球是虎耳草科绣球属灌木，大多高1米左右。',
 'times': '2022-05-02',
 'title': '云赏花 | 共青森林公园这片“雪球”正盛放~'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '云赏花 | 共青森林公园这片“雪球”正盛放~' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '3月31日，浦西封控前一天晚，在徐汇区疾控中心指导下，一支由徐汇区青联委员、区青企协会员携手上海市欧美同学会徐汇分会、青委会成员组成的临时流调小分队在半小时内集结完成。随着疫情防控的形势不断向好，在日常工作中也会遇到一些心态平和、积极乐观面对的上海阿姨和爷叔。',
 'times': '2022-05-02',
 'title': '流调电话里的四月'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '流调电话里的四月' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '现场消毒\u3000\u3000面对疫情期间人手少、任务重的局面，水务事业部还采用数字化巡检设备提高工作效率。',
 'times': '2022-05-02',
 'title': '方舱医院的污水去哪儿了？守牢水环境保护的最后一道防线'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '方舱医院的污水去哪儿了？守牢水环境保护的最' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '为方便市民核酸检测，本市将以“固定采样点 便民采样点 '
         '流动采样点”相结合的方式，在全市优化常态化核酸采样点布局。这两天，位于泰康路瑞金二路路口日月光广场的首个“易检小站”便民核酸采样点已经开始进行采样工作。',
 'times': '2022-05-02',
 'title': '直击黄浦“易检小站”核酸采样现场'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '直击黄浦“易检小站”核酸采样现场' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '这里是上海首个非医疗机构改建的市级方舱医院，也是第一个关闭的市级方舱医院。4月30日傍晚时分，随着最后13位出舱者被静安区派来的大巴接走，中国工程院院士、瑞金医院院长宁光为嘉荷新苑方舱的大门贴上封条。',
 'times': '2022-05-02',
 'title': '关舱！上海首个'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '关舱！上海首个' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '杏花楼同时也在逐步推进全市门店恢复营业，目前已有浦东、闵行等区的13家门店复工，开放线上下单。快速推进复工的还有德兴菜馆，两周前昌里路店恢复外卖的消息在周边社区中引起一阵小激动，几天后复兴荟店也在居民期待中上线。',
 'times': '2022-05-02',
 'title': '上海餐饮企业逐步复工，市民熟悉的“好味道”正在回归'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海餐饮企业逐步复工，市民熟悉的“好味道”' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '昨天上午，第一批出门市民就开始凭证有序外出，小区门口志愿者会对出入证进行核实，并在相应的日期进行打勾标注。居民购买物资后，回到小区后也须再次查验出入证，扫描小区场所码，查验健康码、48小时核酸阴性证明并测量体温。',
 'times': '2022-05-02',
 'title': '防范区的限时限流，一家有几张出门证？街边的馄饨店开门了吗？进超市要 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '防范区的限时限流，一家有几张出门证？街边的' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '我所居住的小区，是一个地处外环线外、单价长期在4万左右徘徊的“房价洼地”。重新分区的小区核酸检测地图，左上角的时间是表示同颜色区域做核酸检测的时间段\u3000\u3000'
         '夏总做的第二件事，就是从头构建志愿者团队的组织架构。有的物资经常是午夜凌晨或是天气恶劣时送达，居委会工作人员和志愿者也会加班清点发放\u3000',
 'times': '2022-05-02',
 'title': '以热爱赴美好｜一个“房价洼地”小区的抗疫手记'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '以热爱赴美好｜一个“房价洼地”小区的抗疫手' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '楼长，一个很多居民楼不曾有或是存在感极弱的角色，在今年春天与团长、志愿者以及所有的一线人员一起支撑起了上海人的封控生活。面对病毒的侵袭，有很多有能力的人愿意和医务工作者一样选择做一名“勇士”，奋战在一线，只是我们的战场在社区。',
 'times': '2022-05-02',
 'title': '上海楼长，平凡英雄'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海楼长，平凡英雄' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '疫情期间，对于居住人口较复杂、人口老龄化程度较高的老城厢旧改地块而言，如何保障物资供应是一个不小的难题。除了物质生活上的关心，征收工作人员还常常通过电话探访，关心居民身体情况，疏导缓解征收地块居民的焦虑恐惧情绪，呵护居民的心理健康，确保被征收居民安全渡过疫情。',
 'times': '2022-05-02',
 'title': '打通老城厢物资供应最后100米，征收所的青年们为旧改居民“拼了”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '打通老城厢物资供应最后100米，征收所的青年们' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '我们小区总共有1500户、4000人左右的居民，其中三分之一是来自不同国家的外籍人士，其中以韩、日、美、加等国的居民为多。今年3月中，上海疫情进入比较严峻的阶段，我和我的团队住在小区居委的办公室内，至今已有一个半月的时间。',
 'times': '2022-05-02',
 'title': '上海居委书记抗疫口述实录：小区封控满月，上海会好的'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海居委书记抗疫口述实录：小区封控满月，上' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '疫情防控期间，快递员、外卖员必须持有电子通行证才能上路接单，为居民配送快递和外卖。经过检查，大部分快递员、外卖员都持有正常的核酸阴性证明和电子通行证，符合防疫规定，满足正常上路通行条件。',
 'times': '2022-05-02',
 'title': '杨浦警方集中整治“黑骑手”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '杨浦警方集中整治“黑骑手”' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '不妨参考以下几点：\u3000\u3000'
         '选择侧开门的，你就可以把机器塞到台下、桌下等角落；选择可以切换冷藏和冷冻模式的，你就可以拥有一个冰箱或一个冰柜；冰箱：零下32°C速冻，真空储存，超薄机身……现在的新冰箱太“卷”了\u3000',
 'times': '2022-05-02',
 'title': '又有一批“网红家电”诞生了！网友：宅家的幸福感是它们给的……'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '又有一批“网红家电”诞生了！网友：宅家的幸' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '疫情期间，长宁区绿化市容局各条线单位，冲锋在城区市容保障最前线。为保障全区生活垃圾的正常中转处置，区废弃物管理所落实疫情防控要求，加强各项人员管理、场所消杀、后勤保障工作，为职工提供良好的工作环境。',
 'times': '2022-05-02',
 'title': '封控期间，长宁这样守护城区的市容环境……'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '封控期间，长宁这样守护城区的市容环境……' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '受疫情的影响，很多车辆停放近一个月未正常使用。1、发动机内机油容易氧化变质 '
         '一般来说机油在发动机里面是有保质期的，由于发动机中的机油多少有些污染。如果长时间闲置就会加剧机油的氧化和变质，特别是水蒸气等水分进入后会迅速乳化机油。',
 'times': '2022-05-02',
 'title': '汽车长期闲置，需要注意些什么？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '汽车长期闲置，需要注意些什么？' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '“保安队长陈步高和另外两位保安‘阳’了，已在18日晚由相关部门安排转运至隔离点。当天下午2点，好消息传来：几位保安已在公司安排下，顺利入住了酒店，继续进行健康监测。',
 'times': '2022-05-02',
 'title': '得知保安队长“阳”了，上海这个小区的居民做了一件事，温暖了很多人……'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '得知保安队长“阳”了，上海这个小区的居民做' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '小区封控管理期间，朱伟始终带头冲在抗疫第一线，每天早出晚归，已经很久没和家人一起吃饭了。“楼组长助理”朱世斐是一位语文老师，每天结束网课后，她便开始忙着帮楼栋里的老年人参与团购。',
 'times': '2022-05-02',
 'title': '物资配送有“公车”、楼组长有“助理”……这个小区防疫工作模式有一套！'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '物资配送有“公车”、楼组长有“助理”……这' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '对此，市大数据中心回应称，此类赋黄码的情况，应该是因为最近一段时间没有做核酸，被列为“应检未检”。对于封控区，每天进行一次核酸采样；管控区采用“3次核酸 '
         '4次抗原”组合筛查方式；防范区采用“1次核酸 6次抗原”组合筛查方式。',
 'times': '2022-05-01',
 'title': '随申码怎么突然变黄了？哪里可以去申诉？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '随申码怎么突然变黄了？哪里可以去申诉？' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': None,
 'times': '2022-05-01',
 'title': '4月30日（0-24时）上海新增本土确诊病例788例、无症状感染者7084例'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '4月30日（0-24时）上海新增本土确诊病例788例、无' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '就好像此前网友们用橙子、橙汁、可乐等做抗原检测实验一样，非人体样本的检测，都会导致抗原检测系统的紊乱。水产品在捕捞、宰杀、加工、销售、运输的各个环节，都可能被新冠病毒污染；但是，新冠病毒不可能感染鱼类。',
 'times': '2022-05-01',
 'title': '团购买到的鱼，需要进行抗原检测吗？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '团购买到的鱼，需要进行抗原检测吗？' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '截至目前，公园绿地方面已累计出动239支队伍，1438人次，消杀绿地1509块（含口袋公园即街心花园417块）。公园绿地内累计消杀擦拭座椅、垃圾桶以及游乐设施等城市家具共计5万余个。另据了解，为确保消杀工作高标准落实，保障全区整体防疫措施的落实和疫情防控的效果，区绿化管理部门在要求相关作业实施单位认真做好消杀工作的同时，也要加强消杀工作与人员的管理。',
 'times': '2022-05-01',
 'title': '闵行50多座公园及1500多块公共绿地完成环境消杀'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '闵行50多座公园及1500多块公共绿地完成环境消杀' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '4月29日一早，徐汇区爱建园小区46号楼的绝大多数居民发现，自己的随申码竟然变黄了。该工作人员表示，如果这两天做了核酸，但还是被赋黄码的，可以通过“随申码”的“我要申诉”功能提交申诉。',
 'times': '2022-05-01',
 'title': '徐汇一防范区楼栋居民百般不解，一夜醒来“随申码”怎么变黄了？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '徐汇一防范区楼栋居民百般不解，一夜醒来“随' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-05-01', 'title': '在上海，他们距离“生死”很近'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '在上海，他们距离“生死”很近' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '帮助对接企业需求，在防疫物资方面，联合15家防疫物资供应商发布了《上海市企业服务云防疫物资供给清单》，为中小企业提供140多种防疫物资产品。除上述举措外，为了畅通供应链、打通堵点卡点，淘宝天猫联动菜鸟，优先解决上海商家的物流问题。',
 'times': '2022-05-01',
 'title': '上海复工复产第二批“白名单”出炉，多种纾困措施出台，大企业和小商家 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海复工复产第二批“白名单”出炉，多种纾困' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '经过认证的上海资讯博主也有类似情况，如@上海吃喝玩乐嗨购、@上海吃喝玩乐播报，IP属地都显示为湖南。今日头条称，平台展示的账号IP属地为用户最近一次发文或评论时的网络位置，账号IP属地以运营商提供信息为准。',
 'times': '2022-05-01',
 'title': '微博、微信、抖音接连上线重磅功能，网红“大型翻车现场”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '微博、微信、抖音接连上线重磅功能，网红“大' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-05-01', 'title': '火力全开！“黑珍珠餐厅”烹饪老年保供餐'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '火力全开！“黑珍珠餐厅”烹饪老年保供餐' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '在《本草纲目》BGM的渲染下，刘畊宏自创的健身口号火遍了全网。网友对刘畊宏的正面情绪在4月24日达到了峰值，因为在这天“周杰伦刘畊宏眼里的浪漫”这一话题登上热搜，引发网友热烈讨论。',
 'times': '2022-05-01',
 'title': '为什么刘畊宏能火？我们分析了微博的175万条信息'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '为什么刘畊宏能火？我们分析了微博的175万条信' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '4月28日晚，网络上流传着一则消息，说上海外滩因为长期封控，都长草了。记者连夜赶往外滩，拍下了这些照片——实际情况是虹口滨江秦皇岛码头段长草了，据环卫工人介绍，此处在疫情前就有嫩芽萌发，春风吹又生，小草生命力旺盛。',
 'times': '2022-05-01',
 'title': '网传外滩长草了？我们连夜去看了看'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '网传外滩长草了？我们连夜去看了看' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:14 [scrapy.core.scraper] ERROR: Error processing {'info': '三阳南货店同样也推出了多款产品，价格从34元-238元不等，既有甜点组合，也有小笼、粽子、豆腐等套餐，产品可谓相当丰富。长春食品商店也推出多款套餐，售价从89元-353元不等，含熟食、糕点、半成品等产品。',
 'times': '2022-05-01',
 'title': '又一批老字号推出美食套餐，应季粽叶渐飘香'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '又一批老字号推出美食套餐，应季粽叶渐飘香' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '”\u3000\u3000'
         '贞贞和兔兔俩人是我们楼的楼组长，做楼道志愿者的时候，我就是跟着她俩混。成为社区志愿者穿上红马甲的那天，贞贞和兔兔欣慰地看着我，满脸笑意，那眼神仿佛看着全村的希望。',
 'times': '2022-05-01',
 'title': '检察志愿者手记：如果不是亲眼所见，我一定会笑这故事编得太假'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '检察志愿者手记：如果不是亲眼所见，我一定会' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '4月18日，经过近4天的紧张改建，徐汇区龙华中路方舱医院交付使用，第二天中午正式开舱，由来自广西的援沪医疗队进驻工作。广西医疗队无法为方舱后勤保障团队开展核酸采样，大华医院便迎难而上，派医护人员为方舱指挥部和工勤团队采样，确保方舱各项工作顺利开展。',
 'times': '2022-05-01',
 'title': '上海阿姨咳嗽时让我“别过来”，本地医院搬来了自家药房……援沪医护眼 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海阿姨咳嗽时让我“别过来”，本地医院搬来' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '2022年4月28日上午，在“老盛昌汤包”胶州路店门口，外卖小哥们排起了长长的队伍，等待取餐，其中还有不少防范区的市民前来购买。据饿了么消息，近一周以来，上海的益丰大药房、国大药房、全家便利店、罗森等医药商超等保供门店外卖营业率持续上升。',
 'times': '2022-05-01',
 'title': '“老字号”汤包店平日一天的单量上线外卖平台一小时就被抢空'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“老字号”汤包店平日一天的单量上线外卖平台' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '”\u3000\u3000'
         '方舱医院是隔离收治新冠肺炎无症状感染者和轻症患者的重要场所。这种情况下，上海市决定，把部分条件较好的方舱医院床位升级改造，用于收治普通型以上患者和高龄感染者。',
 'times': '2022-05-01',
 'title': '老人住进方舱后，我目击了他们的生活和救治'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '老人住进方舱后，我目击了他们的生活和救治' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '此轮上海疫情中，集成电路因其必须连续生产的特殊性，部分龙头企业生产线始终未停。（来源：上海市集成电路行业协会）\u3000\u3000'
         '4月25日，安森美半导体位于上海外高桥保税区内的全球分拨中心正式复工。',
 'times': '2022-05-01',
 'title': '上海芯片产业“武力值”恢复六成靠“团长”？揭秘集成电路敏捷韧性供应 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海芯片产业“武力值”恢复六成靠“团长”？' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '“85后”黄思竞在小区当了一个月的志愿者。楼栋内招募志愿者的时候，我拒绝了一些年纪较大的热心叔叔阿姨们报名，选了包括我在内的4个中年人，承担起楼栋内所有的志愿者工作。4月10日，我居住的楼栋因为有确诊病例成了封控楼栋，这样的楼栋内所有志愿者就也居家了，所有工作都由物业人员承担。',
 'times': '2022-05-01',
 'title': '财务总监在小区当了一个月的志愿者，那些感动和误解都是真的'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '财务总监在小区当了一个月的志愿者，那些感动' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '在微博话题#2022高考倒计时#下的热门里，有这样一句话：乾坤未定，珍惜当下，你我皆是“黑马”。注意到胜利（化名），是记者第一次踏入金山天华路方舱医院，治疗室外的“考试勿扰”与有些嘈杂的病区格格不入。',
 'times': '2022-05-01',
 'title': '高考倒计时不足40天 我在方舱医院遇到了两位高三学生的妈妈'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '高考倒计时不足40天 我在方舱医院遇到了两位高' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '2022年4月29日0—24时，新增本土新冠肺炎确诊病例1249和无症状感染者8932例，其中985例确诊病例为既往无症状感染者转归，264例确诊病例和8932例无症状感染者在隔离管控中发现。',
 'times': '2022-04-30',
 'title': '4月29日（0-24时）上海新增本土确诊病例1249例、无症状感染者8932例，其...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '4月29日（0-24时）上海新增本土确诊病例1249例、' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '比如，老盛昌的冷冻半成品包括菜肉馄饨、鲜肉团子、百叶包、小馄饨、白面刀切、鲜肉汤包、肉包、豆沙包等等。半夜十二点，小陈火速打开APP，果然看见店中的各种口味的龙虾变成了可以下单的状态，连忙点了一份蒜泥小龙虾。',
 'times': '2022-04-30',
 'title': '上海：火锅、汤包、小龙虾…熟悉的外卖回来了，想买得“赶早”！'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海：火锅、汤包、小龙虾…熟悉的外卖回来了' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '建议检测前两小时内最好不吃东西，提前30分钟不喝水、不饮酒、不吃口香糖等，避免采样中可能出现恶心、呕吐等现象。就此，北京佑安医院呼吸与感染科主任医师李侗曾表示，饮食引起核酸假阳性的说法是没有科学依据的。',
 'times': '2022-04-30',
 'title': '核酸检测前喝饮料会假阳性？专家：恰恰相反'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '核酸检测前喝饮料会假阳性？专家：恰恰相反' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '暮春和初夏，正值醉白蔷薇盛放的季节。当谷雨暖风凝露，晓霞乍敛，吹开了鲜艳玲珑的蔷薇花，给古园的深春带来一种别样浓情芬芳。读书堂、疑舫、盆景园、外湖沿岸等处，一团团、一簇簇的蔷薇盛开，荼靡了一季的花事。',
 'times': '2022-04-30',
 'title': '醉白池的蔷薇开了，一起来“云赏”吧→'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '醉白池的蔷薇开了，一起来“云赏”吧→' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '老人儿时在上海长大后随父亲到乡下务农\u3000\u3000'
         '“今年是我离开上海的第60个年头。对上海有着深厚的感情。相信明天你们的生活会明亮起来。汇成一句话：衷心感谢。但因封控做不到。居委会同志都想到了，真使人感动。',
 'times': '2022-04-30',
 'title': '纸条里的上海'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '纸条里的上海' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '4月27日，上海单日新增确诊病例1292例，新增无症状感染者9330例。目前，单日新增确诊病例数相比此前峰值，已下降64%；而单日新增无症状感染者相比此前峰值，也下降了63%。闵行区新增病例数也呈现明显的下降趋势，27日，单日新增无症状感染者数已降至270人，相比此前峰值下降94%。',
 'times': '2022-04-30',
 'title': '这些新规5月1日起施行'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '这些新规5月1日起施行' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '4月27日下午，上海市杨浦区延吉五村的“社区健康大使”陈锡峰，将急需的药品送到了同小区75岁独居老人潘阿婆的手上。日前，为进一步保障重症慢病患者群体就医购药，提升药品配送效率，上海就医保药应急平台正式开通。',
 'times': '2022-04-30',
 'title': '“上海就医保药应急平台”打通医保支付，首位患者当天拿到“救命药”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“上海就医保药应急平台”打通医保支付，首位' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '”\u3000\u3000'
         '研制方负责人、上海人工智能研究院执行院长宋海涛介绍，这样的核酸采样车全市已有30多辆，除了闵行，还开进了浦东、长宁、徐汇。黄浦区目前正紧锣密鼓推进区域内108个常态化核酸采样点布点工作，其中有固定采样点32处，便民采样点65处，流动采样点11处。',
 'times': '2022-04-30',
 'title': '“免费的，还没人排队”！沪上首批常态化核酸采样点“上岗”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“免费的，还没人排队”！沪上首批常态化核酸' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '中国海关总署本月15日曾发布消费提示，提醒消费者暂停食用费列罗集团比利时阿尔隆工厂生产的4类巧克力产品。费列罗中国还表示，费列罗已暂停比利时阿尔隆工厂的生产，并正在与当地食品安全部门积极合作调查沙门氏菌事件。',
 'times': '2022-04-30',
 'title': '多国暴发沙门氏菌疫情，与TA有关，相关产品销往中国'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '多国暴发沙门氏菌疫情，与TA有关，相关产品销' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '3月28日5时起，上海开展了全市新一轮核酸筛查，并以黄浦江为界分区分批实施，目前已满一月。1 '
         '封控初，把绿叶菜都让走后，蔬菜店老板“缺菜了”\u3000\u3000老于的蔬菜店货架重新被填满了。',
 'times': '2022-04-30',
 'title': '30天后，我们回访了这些抗疫的普通人'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '30天后，我们回访了这些抗疫的普通人' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '让他对于隔离期间做菜的难处感同身受。”\u3000\u3000'
         '上线至今，“隔离食用手册”已经收获了600多万次点击，访问量超过70万人。菜谱材料还是会尽量限制在特定范围内。综合自：@人民网@新闻晨报·周到APP（记者：王琛），如有冒犯，敬请联系。',
 'times': '2022-04-30',
 'title': '这份“隔离食用手册”火了！帮助70万人学做菜！赶紧收藏'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '这份“隔离食用手册”火了！帮助70万人学做菜' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '上海日前公布了第一批共534个核酸采样点，将以“固定采样点 便民采样点 '
         '流动采样点”相结合的方式，在全市优化常态化核酸采样点布局。《上海市常态化核酸采样点地图》是基于天地图·上海https://www.shanghai-map.net/空间地理信息平台，对接上海市卫健委发布信息进行空间定位的面向公众的核酸采样点分布地图。',
 'times': '2022-04-30',
 'title': '离你最近的采样点在哪里？《上海市常态化核酸采样点地图》上线'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '离你最近的采样点在哪里？《上海市常态化核酸' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '国家会展中心方舱医院或是世界上最大的巨型方舱医院，在这里，上海集中隔离点医疗救治组组长、上海交通大学医学院附属瑞金医院副院长陈尔真已经连续工作近20天。管理一家巨型方舱，陈尔真每天要协调千头万绪，图为国展中心（上海）方舱医院医疗保障工作协调会\u3000\u3000'
         '4月26日，陈尔真接受了人民日报大江东工作室的采访。',
 'times': '2022-04-30',
 'title': '陈尔真：感染人数正在慢慢下降，方舱医院开始“床等人”！'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '陈尔真：感染人数正在慢慢下降，方舱医院开始' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '事实上，记者查证发现，此次疫情前，保供物资的供应商上海戎阳超市管理有限公司已存在违法问题。目前，针对上海戎阳超市管理有限公司的多个违法行为，相关区市场监管局均已立案调查，将依法严查重处当事人的违法经营行为。',
 'times': '2022-04-30',
 'title': '保供酱鸭有两个生产日期？邻居组织团购却在赚暴利？上海严打发“疫情财 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '保供酱鸭有两个生产日期？邻居组织团购却在赚' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '近日，一则“女孩倒立模仿刘畊宏跳毽子舞”的视频火遍全网，词条“这是宏畊刘吧”一时间登上热搜。2021年，张珂还和上海杂技团的演员们一起，登上了央视元宵晚会的舞台，带来了《战上海》中的压轴杂技表演片段《丰碑》。',
 'times': '2022-04-30',
 'title': '倒立跳刘畊宏毽子舞的女孩火了！她是曾经获得过金小丑奖的上海杂技团演员'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '倒立跳刘畊宏毽子舞的女孩火了！她是曾经获得' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '在重点场所推行“场所码”和“数字哨兵”，是落实新冠肺炎疫情常态化防控的重要举措，是数字化赋能精准防疫的重要手段。将“场所码”下载打印张贴在场所出入口，出入人员只要扫一扫，即可完成人员健康状态核验和场所登记。',
 'times': '2022-04-30',
 'title': '黄浦区在重点场所全面推广使用“场所码”和“数字哨兵”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '黄浦区在重点场所全面推广使用“场所码”和“' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '4月24日下午3点，“滋滋滋”的喷雾器声准时在普陀区长风新村街道的黎金苑小区响起，这略显刺耳的“噪音”却让小区居民无比安心。原来，这群纪律严明、胆大心细的“消杀勇士”，跨越800余里从武汉日夜星驰来到上海，与黎金苑小区结下了一段情谊。',
 'times': '2022-04-30',
 'title': '上海一个居民区里，武汉“消杀铁军”与上海居民双向奔赴的爱'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海一个居民区里，武汉“消杀铁军”与上海居' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '3\u3000\u3000'
         '咪咕视频将持续提供海量优质内容，为上海市民赠送15天视频会员卡，自4月29日起至5月底可通过活动入口免费领取观看。会员领取方式：打开米读APP，书城-',
 'times': '2022-04-30',
 'title': 'e企守“沪”：哔哩哔哩、百视TV、咪咕视频、起点读书等上海互联网企业再...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'e企守“沪”：哔哩哔哩、百视TV、咪咕视频、起' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-29', 'title': '6月30日前 上海常态化核酸检测点实行免费核酸检测'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '6月30日前 上海常态化核酸检测点实行免费核酸检' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '路边一排破败围挡后，堆满被丢弃的苹果',
 'times': '2022-04-29',
 'title': '大批“完好苹果”被扔上海街头引关注，真相是……'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '大批“完好苹果”被扔上海街头引关注，真相是' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-29', 'title': '上海每户每天有60元保供物资标准？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海每户每天有60元保供物资标准？' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-29', 'title': '上海社会面清零进展如何？我们盘点了各区疫情最新走势'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海社会面清零进展如何？我们盘点了各区疫情' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-29', 'title': '上海市民注意 5月份有这些新规即将施行'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海市民注意 5月份有这些新规即将施行' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-29', 'title': '上海市民关心：被隔离工资发不发？受疫情影响企业能否缓发工资？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海市民关心：被隔离工资发不发？受疫情影响' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-29', 'title': '上海实施封控满一个月 新增阳性感染者回落至万例以下'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海实施封控满一个月 新增阳性感染者回落至万' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '网络上流传着一则消息，说上海外滩因为长期封控，都长草了',
 'times': '2022-04-29',
 'title': '网传上海外滩长草了？一起看看寂静的夜外滩'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '网传上海外滩长草了？一起看看寂静的夜外滩' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None,
 'times': '2022-04-29',
 'title': '4月28日（0-24时）上海新增本土确诊病例5487例、无症状感染者9545例'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '4月28日（0-24时）上海新增本土确诊病例5487例、' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '永辉超市、每日优鲜等部分平台将日用品加入了保供套餐，可与食品等捆绑购买。 '
         '天猫、京东等电商平台日用品选择更广，价格平稳，但配送时间相对较慢或不固定。 '
         '饿了么、美团APP等外卖平台的“超市便利”选项，购买日用品后由外卖员送货上门，但部分门店价格偏高，普遍来说，“跑腿费”高于“外卖配送费”。',
 'times': '2022-04-29',
 'title': '卷纸、牙膏、肥皂等日用品怎么买？这些途径可以试试→'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '卷纸、牙膏、肥皂等日用品怎么买？这些途径可' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '封控、核酸、囤菜、居家办公……突如其来的疫情，打破原本的“日常”，也让一些“非常”成为“寻常”。两周多的时间过去了，姜敏离开隔离点返回家中，完成了7天的健康监测，回归团购烧饭、下楼做核酸的生活。',
 'times': '2022-04-29',
 'title': '上海春天·面孔｜确诊后收获陌生善意的女孩：在食物和手机里寻找生活'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海春天·面孔｜确诊后收获陌生善意的女孩：' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '4月27日晚上12点，00后的刘贝贝结束当天的分拣工作，她完成了超过350单的分拣，平均三到四分钟就要搞定一单。美团买菜相关负责人表示，伴随着上海疫情逐步得到控制，在上海政府支持下，美团买菜对于分拣及配送人员进行“饱和式支援”，全力保证市民购物需求。',
 'times': '2022-04-29',
 'title': '上海美团买菜八成站点复工：有站点一天分拣超万单，配送人员增一倍'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海美团买菜八成站点复工：有站点一天分拣超' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-29', 'title': '闭环管理，我在上海师范大学的校园生活'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '闭环管理，我在上海师范大学的校园生活' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '张卉医生手上的那门电话是上海交通大学医学院附属新华医院 '
         '4月28日起推出的“专科医师咨询平台”中的重要组成部分。新华医院新近推出的“专科医师咨询平台”，由专科医师热线电话、互联网医院在线咨询与医院微信矩阵三部分组成。',
 'times': '2022-04-29',
 'title': '上海第一家医院组团式推出专科医师咨询服务！心内、皮肤、眼科等8个专科...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海第一家医院组团式推出专科医师咨询服务！' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '中转箱清运采取的“箱换箱”模式，由专门作业车辆进行整体密封清运，运走原有中转箱，投放空箱，既减少人力消耗，也不易产生路面残留垃圾。后续，长宁区绿化市容局也将根据街镇的需求，增加设置相应的大型生活垃圾中转箱。',
 'times': '2022-04-29',
 'title': '全市开展泡沫塑料、废纸箱等应急专项回收，解决物资发放、团购造成的街 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '全市开展泡沫塑料、废纸箱等应急专项回收，解' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '车辆检修加紧开展了，运营时刻表先排起来了，工作人员开始准备了。”\u3000\u3000'
         '除了要对所有线路进行最低运能的时刻表编排，车队还按照上海市“三区”差异化防控要求，做好可复工复产人员的数据统计工作。眼下，车队正在稳扎稳打做好复工复产准备，要为上海市民提供舒适、高效、优质的公共出行服务。',
 'times': '2022-04-29',
 'title': '运营时刻表先排起来了，上海公交防疫、复工“双线作战”，做到可随时按 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '运营时刻表先排起来了，上海公交防疫、复工“' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '邱永铭，黄浦公安分局淮海中路派出所副所长，但疫情之下，此时他还有另一重身份：黄浦区沪滇友谊方舱医院公安派驻指挥员。这所方舱医院里有三千多名患者，每天有进有出，邱永铭和同事们每天都在超负荷运转，但他一直关注着唐师傅的动向。',
 'times': '2022-04-29',
 'title': '当一名阳性感染者试图逃离方舱……一群陌生人先后“出手”了'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '当一名阳性感染者试图逃离方舱……一群陌生人' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '疫情之下，“社区团购”成为很多嘉定市民获得物资的关键渠道。我觉得，正是我们不断改进方案，居民的满意度越来越高，对我们也愈加信任，因此他们根本不相信私下团购的群体。疫情以来，我加入村里的防疫志愿者队伍，最近小店重开，我又兼起“团长”一职，为村民们订购货品。',
 'times': '2022-04-29',
 'title': '不想当卖货郎的志愿者不是好团长'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '不想当卖货郎的志愿者不是好团长' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '他们每天随叫随到，家电修理、物资配送、维持秩序……因为贴心服务、真诚奉献，被居民亲切地称为“西大男团”。当陆凯健将修整一新的电动轮椅送到老人家里时，陈爷爷高兴极了，连声道谢。',
 'times': '2022-04-29',
 'title': '“不回家”的新晋“男团”，让社区居民赞不绝口'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“不回家”的新晋“男团”，让社区居民赞不绝' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '再小的家，按照自己喜欢的样子去装修，也能得到一个幸福感满满的居所。因为两边都可以用帘子拉上遮住，在开放式的空间当中也保证了卧室的私密性，睡在里面想必也是安全感满满。女孩在客厅打造了一整面的橱柜，用来收纳衣物和日常用品，在这小户型当中争取了较大收纳空间。',
 'times': '2022-04-29',
 'title': '“破局”大通间、公主风卧室、收纳很能打！独居女孩的家只有37㎡，但幸 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“破局”大通间、公主风卧室、收纳很能打！独' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '这两天有网友发现随申码悄悄上线了两个新功能：复工证、通行证 '
         '▽点开自己的随申码在下方图标中向左滑动就出现了两个新的功能一个是复工证，一个是通行证\u3000'
         '为加强电商平台、快递等行业从业人员健康管理，在“随申码”页面上线“上海市保供配送人员通行证”和“邮政快递公司寄递人员电子通行证”，此两证统一简称为“通行证”。',
 'times': '2022-04-29',
 'title': '随申办上线复工证、通行证，能申请吗？回应→'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '随申办上线复工证、通行证，能申请吗？回应→' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '记者了解到，不少学生跟着父母和长辈一起居家劳动，成了很多申城孩子的美好时光。亲子劳动不仅帮助孩子养成做家务的好习惯，还对父母多了一份理解和体谅。奉中附小的全体导师们在各自“好朋友”群，发动学生们利用周末时间积极参与家务劳动。',
 'times': '2022-04-29',
 'title': '学做豆腐、学发豆芽、为父母做早餐……疫情下的申城中小学生变身家务“ ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '学做豆腐、学发豆芽、为父母做早餐……疫情下' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '3个女孩子，大学是北大同一个寝室的，毕业10年后重新聚在一起，聊了聊彼此的近况。33岁的佳佳，已婚未育，研究生是在英国读的，之后也曾在欧洲和日本工作，目前在国内做法律服务行业，是销售主管；',
 'times': '2022-04-29',
 'title': '“北大同寝室3人毕业的10年后”引热议：1个起点，3种相似的结局'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“北大同寝室3人毕业的10年后”引热议：1个起点' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '顾女士说，封控前，她母亲的放疗正做到一半，多亏了“生命巴士”，治疗一点都没耽误。”\u3000\u3000'
         '回忆起第一趟乘坐“生命巴士”，顾女士说，没想到会是一辆50座的大巴，看着车子兜兜转转接送患者，心里特别感动。',
 'times': '2022-04-29',
 'title': '兜底送重病患者就医，松江开出了一趟“生命巴士”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '兜底送重病患者就医，松江开出了一趟“生命巴' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '贴文配图显示一个名为“维为道来张维为”的微博账号截图，以及一些网友冷嘲热讽的留言评论。”\u3000\u3000'
         '蒋丞稷曾是男子100米蝶泳的原亚洲纪录保持者，1996年奥运会获男子50米自由泳和100米蝶泳两项第四名，这是当时中国男子游泳在奥运会上取得的最好成绩。',
 'times': '2022-04-29',
 'title': '张维为一怒之下清空微博？蒋丞稷做志愿者摔瘫痪？本人澄清'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '张维为一怒之下清空微博？蒋丞稷做志愿者摔瘫' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-29', 'title': '穿上“大白”仍要当心感染，10条禁忌请记牢→'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '穿上“大白”仍要当心感染，10条禁忌请记牢→' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '为了让社区居民及时知晓小区情况、保障居民们正常生活，航天新苑居委在第一时间组建了“疫情防控志愿者群”。周阿姨和陈师傅表示身为党员志愿者，他们会积极参与社区一线工作，冲锋在第一线承担疫情防控任务，为社区疫情出一份力，为居民提供服务。',
 'times': '2022-04-29',
 'title': '拧成一股绳亲如一家人！徐汇这个小区有点暖→'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '拧成一股绳亲如一家人！徐汇这个小区有点暖→' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '对话中的“小陈”名叫陈洁，是漕河泾街道康州小区志愿者中的一员。据了解，漕河泾街道的康州小区是一个老小区，老龄化比例高，有的楼栋里，甚至一半住户是无子女在身边的高龄老人。',
 'times': '2022-04-29',
 'title': '在这个老龄化小区，居家办公的他们挥洒青春最美的模样'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '在这个老龄化小区，居家办公的他们挥洒青春最' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-29', 'title': '化身“配药侠”，送上救命药，这群黄浦青年在行动'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '化身“配药侠”，送上救命药，这群黄浦青年在' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '3月21日，家所在小区有居民核酸出现异常，小区再次进入闭环管理，在向所在居民区申请参与疫情防控无回复后，我开始了居家隔离。4月4日，连日来的核酸大筛查，要感谢来自浦东的医护，来自安徽的医护，以及社会上一些医疗机构的医护，他们同样起早贪黑为居民们做服务。',
 'times': '2022-04-29',
 'title': '一名社会工作者的这54天……'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '一名社会工作者的这54天……' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-29', 'title': '税控盘不在身边？登录电子税务局也能查看开票信息哦'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '税控盘不在身边？登录电子税务局也能查看开票' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '一位曾经在上海学习生活过的年轻人，用程序员的思维尝试给人们在疫情的阴霾下带来一丝亮光。网页截图\u3000\u3000'
         '说起开发小工具的契机，云游君表示初期灵感来自居住于上海的本科同学和他自己对疫情的亲身体会。',
 'times': '2022-04-29',
 'title': '这个叫“隔离食用手册”的做菜小工具帮了50万人，你也可以试一下'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '这个叫“隔离食用手册”的做菜小工具帮了50万' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '王骁说这是“三一简报”“创刊”以来最轰动的一期，“鼓士气、扬正气、颂美德、显楼情，守护31号楼”是他创设“三一简报”的初衷。好邻居遇见平台补货及时提醒，简报上也立刻点赞“遇见补品一声吼，左邻右舍都吃肉” '
         '……',
 'times': '2022-04-29',
 'title': '太有排面了！居家抗疫，13岁上海小囡的生日居然这么过……'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '太有排面了！居家抗疫，13岁上海小囡的生日居' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-29', 'title': '看到“大白”身上的祝寿图文，90岁住院老奶奶笑了'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '看到“大白”身上的祝寿图文，90岁住院老奶奶' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '杏花楼、沈大成、哈氏、德兴菜馆等多家老字号推出团购套餐',
 'times': '2022-04-28',
 'title': '沪上老字号加紧复工，加入“外卖套餐”，粽子上新了'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪上老字号加紧复工，加入“外卖套餐”，粽子' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '已有12个国家报告不明病因的儿童急性肝炎，主要集中在欧洲',
 'times': '2022-04-28',
 'title': '专家：上海目前未出现不明病因儿童肝炎病例'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '专家：上海目前未出现不明病因儿童肝炎病例' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '针对规范劳动用工、保障工资支付等问题，《工作指引》逐条明确了法律适用',
 'times': '2022-04-28',
 'title': '上海：劳动者依法隔离期间，企业按正常劳动支付其工资'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海：劳动者依法隔离期间，企业按正常劳动支' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': None,
 'times': '2022-04-28',
 'title': '4月27日（0-24时）上海新增1292例本土新冠肺炎确诊病例，新增9330例本土...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '4月27日（0-24时）上海新增1292例本土新冠肺炎确' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '奉贤区第一批“双联双进 '
         '无疫小区（村组）”共有359个小区，涉及113个居委，其中23个居委为全小区创建；1799个村民小组，涉及141个村，其中51个村为整村创建。3月底以来，华严村坚持党建引领，提级管理，做实管控措施，落实服务上门，强化托底保障，以严密的防疫举措推进“无疫村组”建设。',
 'times': '2022-04-28',
 'title': '“无疫小区”防疫工作放大招！南桥镇这样做→'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“无疫小区”防疫工作放大招！南桥镇这样做→' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '位于徐家汇街道爱华居委的爱博大厦属于老式电梯房，两梯七户的房型，使得一栋居民楼里聚集了83户居民，约200多人。这次物资捐赠，孙先生也特意多订了一些，为的就是给其他楼道里的孤老、有困难的群众也送去一份温暖。',
 'times': '2022-04-28',
 'title': '83户居民，10天物资，免费赠送！这位“中国好邻居”藏不住了'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '83户居民，10天物资，免费赠送！这位“中国好邻' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '德兴菜馆昌里路店于4月14日率先恢复了社区外卖服务，每日为周边邻里供应老字号的平价美食。其中馒头粽子套餐价格为98元，包含叉烧包、银丝卷、高庄馒头、黑洋酥包、蛋黄青团、袋装鲜肉粽、袋装豆沙粽。',
 'times': '2022-04-28',
 'title': '有的一份起送！不涨价！这些上海老字号率先复工→'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '有的一份起送！不涨价！这些上海老字号率先复' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '43岁的石阿姨一周前因持续高热收治于松江区的一家医院，后经上海交通大学医学院附属瑞金医院远程会诊，于4月23日以“感染性心内膜炎”收治于心脏外科监护室。↓↓↓\u3000\u3000'
         '4月16日，李先生已经强忍了三天的腹痛，情况没有好转，反而有加重趋势，最终由120送入上海十院急诊。',
 'times': '2022-04-28',
 'title': '瑞金医院全面恢复医疗服务！这家医院最多一天接了114辆120'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '瑞金医院全面恢复医疗服务！这家医院最多一天' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '对于同处家中的上海市民，她想说，面对困难，大家要有强大的精神，和一颗勇敢的心。写诗，画画，拍视频，做中国菜……唐曦兰自有一套文艺又充实的“居家指南”。自高中在俄罗斯的孔子学院接触到中文和中国文化后，唐曦兰对这一有着悠久历史的东方国度产生了向往。',
 'times': '2022-04-28',
 'title': '“面对困难，要有一颗勇敢的心”，俄罗斯女诗人眼中的上海春天'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“面对困难，要有一颗勇敢的心”，俄罗斯女诗' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '有网友晒出一段谷爱凌在跑步中被一名男子拦截合影的视频。该男子不但在自拍时扯下了口罩，还在谷爱凌配合完成合影、准备起身继续跑步时，跨步拦住了谷爱凌不让她走。谷爱凌当天穿的是比较清凉的运动装，而该男子在拦截动作中疑似有肢体接触，能看出谷爱凌的表情十分惊慌。',
 'times': '2022-04-28',
 'title': '网友怒了，“快放开我的朋友谷爱凌！”男子道歉了，但又好像没道歉'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '网友怒了，“快放开我的朋友谷爱凌！”男子道' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '4月26日晚，上海各级市场监管部门再通报一批保供物资、社区团购等方面的产品质量、食品安全投诉举报处理情况。近日，有小区居民反映团购套餐内有超过保质期的冷冻包装鸡翅，浦东新区市场监管局第一时间展开调查。',
 'times': '2022-04-28',
 'title': '团购鸡翅过期8个月，封控小区盒饭里有寄生虫？新一批监管调查情况公布'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '团购鸡翅过期8个月，封控小区盒饭里有寄生虫？' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '编者按：作为中国对外开放的重要窗口，上海以其国际化的氛围以及多元的文化环境吸引了大量境外人员来沪工作和生活。来自韩国的朴昌柱在上海生活了近20年，他现在居住的锦绣江南小区，位于闵行区虹泉路韩国街附近，韩国籍居民约占1/3。',
 'times': '2022-04-28',
 'title': '上海外籍志愿者抗疫故事'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海外籍志愿者抗疫故事' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '简单来说，如果你的核酸报告出现“气膜”字样，就意味着你的这份核酸样本的检测工作是在“气膜式检测实验室”里完成的。在张江科学城的美特斯邦威园区，浙江援沪医疗队援建了一座日核酸检测能力达10万管的气膜实验室。',
 'times': '2022-04-28',
 'title': '“气膜”是什么？你的核酸报告，出自“充气式城堡”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“气膜”是什么？你的核酸报告，出自“充气式' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '今天是世界知识产权日，上海海关发布知识产权保护五大典型案例。经上海海关综合处联系权利人尤尼维瑟城电影制片厂有限责任公司，权利人确认该批口罩系侵犯其“小黄人”动画形象著作权的货物。',
 'times': '2022-04-28',
 'title': '“香奈儿”涤纶布、大牌汽配、“小黄人”口罩，这些假冒进出口商品难逃 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“香奈儿”涤纶布、大牌汽配、“小黄人”口罩' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '区房管局住房保障科的鲍玉婷，居住在一个有着25栋楼、2500多户，共计4700多人的大型居住小区。”\u3000\u3000'
         '鲍玉婷告诉记者，当时整栋楼实际住了多少人，老人和小孩占比多少，都没有确切数字。',
 'times': '2022-04-28',
 'title': '在一栋78户近200人的楼栋做楼长，是什么体验？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '在一栋78户近200人的楼栋做楼长，是什么体验？' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '这些天，黄浦的大街小巷有这样一群“大白”身影。”自从黄浦二征所群里，发出加入疫情防控一线号召后，作为一名复员军人，王新宇没跟家人商量，就主动报名加入志愿者队伍。”\u3000\u3000'
         '作为一名女性志愿者，祁夕花参与到抗疫一线已近一个月了。',
 'times': '2022-04-28',
 'title': '从“50后”到“90后”，黄浦旧改人正在“疫”线'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '从“50后”到“90后”，黄浦旧改人正在“疫”线' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '作为当前市民生活物资保障的重要力量，保供人员吃住无忧，才能更好地做好市民“菜篮子”的保障工作。4月25日，在彭浦新村街道的协助下，区商务委积极对接相关资源，为美团买菜解决20名外卖骑手的酒店住宿问题，避免骑手在极端恶劣天气露天留宿。',
 'times': '2022-04-28',
 'title': '静安区落实多个集中住宿点，为骑手提供温暖住处'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '静安区落实多个集中住宿点，为骑手提供温暖住' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '也找到了那位哭着送她的居民区书记\u3000\u3000'
         '武阿姨——今年70岁，曾经也是一位社区工作者，现在是浦东新区沪东新村街道北小区居民区第二支部的支部书记。',
 'times': '2022-04-28',
 'title': '朋友圈里那位乐观、善良的上海阿姨，我们找到了！还有哭着送她的居民区书记'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '朋友圈里那位乐观、善良的上海阿姨，我们找到' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '上海疫情牵动着广西社会各界爱心人士的心，4月22日，由80家广西爱心食品企业自发捐助的4万份爱心物资从南宁发车前往上海，支援上海的民生保障工作。25日中午，通过直达专列50个小时的运输，广西驰援上海抗疫保供的爱心物资运抵铁路上海杨浦货站。',
 'times': '2022-04-28',
 'title': '螺蛳粉、海鸭蛋、果蔬干……4万份广西援沪物资乘专列抵达上海徐汇'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '螺蛳粉、海鸭蛋、果蔬干……4万份广西援沪物资' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '新冠肺炎疫情袭击上海，全城按下“慢行键”。周典回忆，早在3月20日起，公司就陆续有同事因为小区封控和工作需要在办公室过夜。疫情暴发前，公司给全体员工都采购了应急防疫保障物资，比如睡袋、毛毯、洗漱包、口罩、消毒用品等，以备不时之需。',
 'times': '2022-04-28',
 'title': '封控近一个月，整栋办公大厦没有出现阳性'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '封控近一个月，整栋办公大厦没有出现阳性' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:15 [scrapy.core.scraper] ERROR: Error processing {'info': '如果抗原检测结果为阳性，使用过的拭子、采样管、检测卡等，应装入密封袋，后续交由管理人员处理。隔离观察人员不论结果阴性还是阳性，使用后的拭子、采样管、检测卡等均装入密封袋，由管理人员处理。',
 'times': '2022-04-28',
 'title': '划重点！快来get“捅鼻子”的正确姿势'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '划重点！快来get“捅鼻子”的正确姿势' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '为方便市民核酸检测，上海将以“固定采样点 便民采样点 '
         '流动采样点”相结合的方式，在全市优化常态化核酸采样点布局。在12号线国际客运中心站白玉兰网球场旁，记者看到虹口区的一处便民核酸采样点已经开始投入使用。',
 'times': '2022-04-28',
 'title': '上海便民核酸采样点什么样？记者带你现场体验'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海便民核酸采样点什么样？记者带你现场体验' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '2022年4月2日，第十届中国花博会复兴馆方舱（简称“复兴馆方舱”）全部建成；4月4日，首批病患入住；4月21日，当日入院360人、出院400人，实现了出院人数大于入院人数的正循环。此时此刻，参与方舱医院建设的市住房城乡建设管理委驻项目现场指挥部同志，回忆起那段艰辛的建设过程，又不禁感慨万千。',
 'times': '2022-04-28',
 'title': '建在花博会园区的方舱！'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '建在花博会园区的方舱！' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '4月26日，全市封控区、管控区和防范区“三区”人员开展全员核酸筛查。记者了解到，现场负责采样的“大白”们来自安徽宿州，历经8小时的路程奔波，昨天晚上刚刚抵达上海，今早6点就赶到小区做采样准备。',
 'times': '2022-04-28',
 'title': '直击杨浦“三区”核酸筛查现场→'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '直击杨浦“三区”核酸筛查现场→' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '4月15日下午，李嘉薇发出“吸痰管告急”的求助信息时，几乎快要死心了。4月16日18时，上海市徐汇公安分局（后称“徐汇分局”）民警黄俊接到李俊的求助电话时，五箱吸痰管已在上海虹桥高铁站滞留了1小时17分钟。',
 'times': '2022-04-28',
 'title': '一根吸痰管的接力｜当渐冻症群体的“救命管”告急'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '一根吸痰管的接力｜当渐冻症群体的“救命管”' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '开展环境核酸检测，搬运、盘点防疫物资，做好物品消杀静置……这是女子所警务保障科民警吴梦秋的日常。为坚决打赢场所疫情防控阻击战，吴梦秋深知，每一件看似平凡的“小事”，都意味着责任重大。',
 'times': '2022-04-28',
 'title': '她们，在防疫战场上重塑“精致”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '她们，在防疫战场上重塑“精致”' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '娃去方舱那天，我在她箱子里塞了卤蛋和水果，没想到她竟然学会了合理安排，单日补充维生素，双日就增加蛋白质。妈妈：娃整整瘦了六斤，她一直有些挑食，方舱的饭菜也不太吃得惯。',
 'times': '2022-04-28',
 'title': '方舱九夜的A面与B面'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '方舱九夜的A面与B面' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '4月11日下午1点半，我背着书包、拖着行李、扛着睡袋，来到虹桥街道荣华居委会荣一工作站，开始了我的市级机关公务员下沉一线日子。不少日本居民在古北一带开餐馆，反正现在也没有生意，店开着更浪费钱，于是索性就安安心心在小区待着。',
 'times': '2022-04-28',
 'title': '曾去伊朗抗疫的上海公务员：社区老外嚷“憋了很久”，我该怎么办'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '曾去伊朗抗疫的上海公务员：社区老外嚷“憋了' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '上海疫情仍在高位波动，连日来，高频的全员核酸筛查，对上海核酸检测能力提出巨大挑战。市经信委产业投资处透露，支撑当下巨量核酸检测需求的，是上海60余家检测机构、70余个检测点和近万名工作人员。',
 'times': '2022-04-28',
 'title': '揭秘上海实际核酸检测能力，3月初是每天100万管，现已迅速扩增到……'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '揭秘上海实际核酸检测能力，3月初是每天100万管' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '面对群众“菜篮子”“米袋子”的“难点”“痛点”，上海保供力量不断加大供应、打通堵点、提升服务，创新保供方式，部分居民生活物资紧张局面正在得到有效缓解。百联南方巧将门店场地资源转变为麦德龙的前置仓，以支撑其在线订购业务。',
 'times': '2022-04-28',
 'title': '“狮子头”、大排等面“浇头”“团”起来，批发市场、菜市场也开始启动复市'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '“狮子头”、大排等面“浇头”“团”起来，批' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-28', 'title': '发放保供物资失职渎职，3名干部被问责'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '发放保供物资失职渎职，3名干部被问责' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-28', 'title': '又有3个区首次社会面清零！哪里可申请复工证？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '又有3个区首次社会面清零！哪里可申请复工证？' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '今年浦东8424西瓜26日起上市，较去年提前5天左右',
 'times': '2022-04-28',
 'title': '上海8424西瓜上市，价格与去年持平，可团购！'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海8424西瓜上市，价格与去年持平，可团购！' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '孩子们该如何保护自己的眼睛呢？',
 'times': '2022-04-27',
 'title': '居家学习护眼好方法 保护孩子的眼睛和保护健康同样重要'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '居家学习护眼好方法 保护孩子的眼睛和保护健康' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-27', 'title': '方舱开始“床等人”！如何加强重症病例救治，竭力避免死亡？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '方舱开始“床等人”！如何加强重症病例救治，' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-27', 'title': '做核酸检测时如何减少感染风险？'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '做核酸检测时如何减少感染风险？' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-27', 'title': '又能开心的买买买了？ 上海快递正式重启'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '又能开心的买买买了？ 上海快递正式重启' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '上海市启动清零攻坚行动以来，效果日益显现',
 'times': '2022-04-27',
 'title': '上海将对社会面基本清零的区实施“有限人员、有限区域、有限活动”'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海将对社会面基本清零的区实施“有限人员、' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': None, 'times': '2022-04-27', 'title': '方舱里来了可爱的“团宠”，“铲屎官”：互相治愈！'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '方舱里来了可爱的“团宠”，“铲屎官”：互相' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': None,
 'times': '2022-04-27',
 'title': '4月26日（0-24时）上海新增1606例本土新冠肺炎确诊病例，新增11956例本 ...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '4月26日（0-24时）上海新增1606例本土新冠肺炎确' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
2022-05-05 21:46:16 [scrapy.core.scraper] ERROR: Error processing {'info': '截至上周末4月23日，80%-90%家乐福上海门店恢复线上营业，目前还有少数门店正在等待环境评测或等待环境评测报告中，预计5月1日前，家乐福上海所有的门店恢复线上营业。线下门店开业规划上，家乐福根据上海各区情况，正在做门店的线下恢复营业的规划及进度，将按照进度有序的推进线下门店的复工准备工作。',
 'times': '2022-04-27',
 'title': '上海大卖场复工中！沃尔玛、家乐福超80%门店已恢复线上营业，大润发已有...'}
Traceback (most recent call last):
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 42, in process_item
    self.cursor.execute(sql,(
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 148, in execute
    result = self._query(query)
  File "D:\python3.8\lib\site-packages\pymysql\cursors.py", line 310, in _query
    conn.query(q)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 548, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 775, in _read_query_result
    result.read()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 1156, in read
    first_packet = self.connection._read_packet()
  File "D:\python3.8\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "D:\python3.8\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "D:\python3.8\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上海大卖场复工中！沃尔玛、家乐福超80%门店已' for key 'PRIMARY'")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python3.8\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\python3.8\lib\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\站点项目\xinwen\xinwen\pipelines.py", line 50, in process_item
    print('信息写入错误%s-%s'%(item['url'],e))
  File "D:\python3.8\lib\site-packages\scrapy\item.py", line 79, in __getitem__
    return self._values[key]
KeyError: 'url'
